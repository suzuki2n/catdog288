機械学習手順


画像分類は教師なし学習ではできない。
ラベル付けは手作業で行う。
教師あり学習で特徴量を抽出するのが大変なので、ディープラーニングを使うしかない。

ディープラーニングを使うにあたり、GPUを使えるようにしないといけない。
まず、GPUがNVIDIAのRTX3060以上が必要。
使う前に準備がいる
①ドライバーの最新版に更新
②windowsも最新版になっているか確認、Visual C++ 再頒布可能パッケージの「x64」 をダウンロード＆インストール
③ CUDA 11.2（推奨）とcuDNN 8.1（推奨）をインストールして環境変数を設定する必要がある
④GPUを認識してくれているかを確認

①はNVIDIAのアカウントが必要

【バージョン選びの注意点】
TensorFlow 2.10 を使うなら、CUDA 11.2 + cuDNN 8.1 あたりが安全ニャ。
CUDA 11.8 / cuDNN 8.8 を使いたいなら、TensorFlow 2.11以降にするとGPU対応してないからダメ。
【ダウントード先】
CUDA 11.2 ダウンロードリンク
CUDA 11.2は以下のリンクからダウンロードできます：
https://developer.nvidia.com/cuda-11.2.0-download-archive
上記のページで以下の選択を行ってください：

オペレーティングシステム：Windows
アーキテクチャ：x86_64
バージョン：お使いのWindowsバージョン10でよい
インストーラタイプ：exe (local)

cuDNN 8.1 ダウンロードリンク
cuDNNをダウンロードするには、NVIDIAデベロッパーアカウントが必要です。以下の手順で進めてください：

https://developer.nvidia.com/cudnn にアクセス
NVIDIAアカウントでログイン
"Archived cuDNN Releases" をクリック
"Download cuDNN v8.1.1 (January 26th, 2021), for CUDA 11.0, 11.1 and 11.2" を探して選択
"cuDNN Library for Windows (x86)" をダウンロード

【パス通しで重要なところ】
cuDNN Libraryを開いて、binとlib\x64とincludeのフォルダ内のファイルをそれぞれ全部ここへコピーすること
cudnn64_8.dll → C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\bin\

cudnn.h → C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\include\

cudnn.lib → C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\lib\x64\

【ライブラリーのインストール】
【重要】
tensorflow-gpu==2.10
NumPy のバージョンを 1.23.5 に固定して、正しく動作する環境を作ります。

python --version
python -m venv myvenv
myvenv\Scripts\Activate
仮想環境を終了するときはdiactivate
pip install pandas scikit-learn matplotlib jupyter scipy
pip install numpy==1.23.5
pip install tensorflow==2.10.0
pip install opencv-python
python.exe -m pip install --upgrade pip

【バージョンの確認】
gpu_len.ipynbを実行したらGPUを認識しているか、tensorFlowのバージョンも確認できるようにしてある。
インストール ボタンをクリックすると、自動で ipykernel がインストールされます。

🧭 やることの全体の流れ（犬猫分類）
手順	内容
①	画像データの準備（犬と猫フォルダに分ける）
②	ImageDataGeneratorで画像を前処理（リサイズや正規化）
③	CNNモデルを作成（Keras Sequential API）
④	モデルをコンパイル（損失関数・最適化）
⑤	モデルを訓練（.fit()）
⑥	評価と予測をしてみる
⑦	精度が低ければ改善（データ数・モデル構造・正則化など）


まず、データセットを8対2に分けることから始める

mkdir_learning.pyで振り分け
リサイズの方はフルパスでコード書いてある

【グラフの文字化け対策】
フォントのインストールまたは利用可能フォントの確認
import matplotlib.pyplot as plt
Matplotlibのフォント設定 (plt.rcParams['font.family'] など)
マイナス記号の文字化け対策 (plt.rcParams['axes.unicode_minus'] = False)

【グラフの読み方の詳細
横軸：エポック数（epochs_range）

エポックが進むにつれて、モデルはデータ全体を何回学習したかを示しているにゃ。

縦軸：評価指標（精度または損失）

精度の場合は、0〜1の範囲で高いほど良いにゃ。

損失の場合は、値が低いほど良いにゃ。

訓練時の変化

一般に、訓練精度（青い線）はエポックが進むにつれて徐々に上がり、損失は下がっていくはずだにゃ。

検証精度（オレンジの線）は、訓練精度ほど高くならない場合が多いが、同じような傾向で改善していけば良い状態にゃ。

モデル作成時にvalidationフォルダの画像でやった小テストができたかどうかのグラフ。

 一般的な画像分類のサイズ事情

用途	よく使われるサイズ
CIFAR-10/100（小さい物体分類）	32×32
MNIST（手書き数字）	28×28
軽量な猫犬分類（入門）	64×64 ～ 128×128
ImageNetレベル（本格分類）	224×224, 299×299（ResNet, Inception用）


【質問1】画像枚数とレイヤー数の目安
✅ 基本の考え方
画像が少ない場合：シンプルなモデル（2〜3層）

画像が多い場合（1万〜数十万枚）：深いモデル（4〜6層、時にはResNetなど）

画像枚数	適したConv層数	コメント
~5,000枚	2〜3層	小さなモデルで十分。過学習に注意
~20,000枚（今）	3〜5層	中規模モデル（今の構成でOK）
数十万枚（今後）	5〜8層、またはResNet等	大規模モデル。BatchNormやDropout必須

❗注意：「レイヤー数が多い＝精度が高い」ではなく、「情報に合った深さが重要」です。

🧠【質問2】Dense層の数とサイズの決め方
✅ 基本の流れ
Conv層で特徴を抽出 → Flatten → Dense層で分類
Dense層の数やサイズは **特徴の「まとめ方」や「複雑さ」**によって変えます。

条件	Dense層の例
2クラス・少画像（〜5,000枚）	Dense(128) → Dense(1)
中画像（〜25,000枚）	Dense(256) → Dense(1) or Dense(512→256→1)
多クラス（11クラス）	Dense(512→256→128→11)（softmaxで出力）

✅ 多クラス分類なら最後は Dense(11, activation='softmax') に変更！

🧠【質問3】Dropoutはどこに何回入れるべき？
✅ Dropoutの目的：過学習を防ぐための「ゆるめのサボり処理」
位置	目的	推奨値
Conv層のあと（1〜2回）	特徴抽出の途中でランダム遮断	Dropout(0.25〜0.3)
Dense層の前（1回以上）	分類の重みをサボらせる	Dropout(0.4〜0.5)
合計で2〜3回	通常の画像分類ではこれくらいが多い	-

💡目安：
python
コピーする
編集する
Conv2D(128, ...)  
MaxPooling2D()  
Dropout(0.25)     ← ここ！

...  
Flatten()  
Dense(512, activation='relu')  
Dropout(0.5)      ← ここも！
❗多すぎても学習が進まないので、基本は「Conv系で1回」「Dense前で1回以上」で十分です。

🔧【今後のための設計案（11クラス分類対応）】
python
コピーする
編集する
model = Sequential([
    Conv2D(64, 3, activation='relu', padding='same', input_shape=(224, 224, 3)),
    MaxPooling2D(2),
    Dropout(0.25),

    Conv2D(128, 3, activation='relu', padding='same'),
    MaxPooling2D(2),

    Conv2D(256, 3, activation='relu', padding='same'),
    MaxPooling2D(2),
    Dropout(0.3),

    Conv2D(512, 3, activation='relu', padding='same'),
    MaxPooling2D(2),

    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(11, activation='softmax')  # ← 多クラス分類の出力層
])
✅貝主さんへのおすすめステップ
今の2クラスモデルにDropoutとDense層を1つずつ増やす

精度・学習曲線を確認（過学習の有無）

11分類モデルに備えて、出力層や活性化関数をsoftmaxに切り替えて練習