{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# „Ç∑„Éº„ÉâÂÄ§„ÇíÂõ∫ÂÆö\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# üê±üê∂ ÁîªÂÉèÂàÜÈ°û„É¢„Éá„É´„ÅÆÂ≠¶Áøí\n",
    "print(Sequential)\n",
    "# GPU„Åå„ÅÇ„Çã„ÅãÁ¢∫Ë™ç„Åó„Å¶„ÄÅ„ÅÇ„Çå„Å∞„É°„É¢„É™Âà∂Èôê\n",
    "print(device_lib.list_local_devices())\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"‚úÖ GPU„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åó„Åü\")\n",
    "    try:\n",
    "        # ÂãïÁöÑ„É°„É¢„É™Ââ≤„ÇäÂΩì„Å¶„ÇíÊúâÂäπÂåñ\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"‚úÖ GPU„É°„É¢„É™„ÅÆÂãïÁöÑÂâ≤„ÇäÂΩì„Å¶„ÇíË®≠ÂÆö„Åó„Åæ„Åó„Åü\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"‚ùå „É°„É¢„É™Ë®≠ÂÆö„Å´Â§±Êïó„Åó„Åæ„Åó„ÅüÔºö\", e)\n",
    "        \n",
    "# üü° „Åì„Åì„Å´Ë®≠ÂÆö„Çí„Åæ„Å®„ÇÅ\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "BATCH_SIZE = 12 # 1Âõû„ÅÆÂ≠¶Áøí„Åß‰Ωø„ÅÜÁîªÂÉè„ÅÆÊûöÊï∞\n",
    "EPOCHS = 50 # „ÄåÂÖ®ÈÉ®„ÅÆÁîªÂÉè √ó 3Âë®„Äç„ÇíÂ≠¶Áøí\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)  # ÁîªÂÉè„ÅÆÁ∏¶„ÉªÊ®™„Éª„ÉÅ„É£„É≥„Éç„É´Êï∞\n",
    "\n",
    "train_dir = 'dataset/train'\n",
    "val_dir = 'dataset/validation'\n",
    "\n",
    "# üìÅ „Éá„Éº„Çø„ÅÆÂâçÂá¶ÁêÜ\n",
    "# Ë®ìÁ∑¥Áî®„Ç∏„Çß„Éç„É¨„Éº„Çø„ÉºÔºà„Ç™„Éº„Ç∞„É°„É≥„ÉÜ„Éº„Ç∑„Éß„É≥‰ªò„ÅçÔºâÔºàÂõûËª¢„ÇÑ„Ç∫„Éº„É†„Å™„Å©Ôºâ„Çí„Åã„Åë„Å™„Åå„Çâ„ÄÅ„É©„É≥„ÉÄ„É†„Å´ÁîªÂÉè„ÇíÂèñ„ÇäÂá∫„Åó„Å¶Â≠¶Áøí„Åï„Åõ„Çã\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # rescale=1./255,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    rotation_range=15,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# „Éá„Ç£„É¨„ÇØ„Éà„É™„Åã„ÇâÁîªÂÉè„ÇíË™≠„ÅøËæº„ÇÄ\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # Ë®ìÁ∑¥„Éá„Éº„Çø„ÅÆ„Éë„Çπ\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=seed_value\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    "    seed=seed_value # ‰π±Êï∞„Ç∑„Éº„Éâ„ÇíÂõ∫ÂÆö\n",
    "    # shuffle=False, # „Ç∑„É£„ÉÉ„Éï„É´„Åó„Å™„ÅÑÂ†¥Âêà„ÅØ„ÄÅTrue„Å´„Åô„Çã„Å®„Ç®„É©„Éº„Å´„Å™„Çã„ÅÆ„ÅßÊ≥®ÊÑè\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Ë®ìÁ∑¥„Éá„Éº„ÇøÊï∞: {train_generator.samples}\")\n",
    "print(f\"‚úÖ Ê§úË®º„Éá„Éº„ÇøÊï∞: {val_generator.samples}\")\n",
    "print(f\"‚úÖ „ÇØ„É©„Çπ: {train_generator.class_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† „É¢„Éá„É´ÊßãÁØâ\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ResNet50„ÅÆ„Éô„Éº„Çπ„É¢„Éá„É´ÔºàImageNetÂ≠¶ÁøíÊ∏à„ÅøÔºâ„Çí‰Ωø„ÅÜ\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Ëª¢ÁßªÂ≠¶Áøí„ÅÆ„Åü„ÇÅ„ÄÅ„Éô„Éº„Çπ„É¢„Éá„É´„ÅÆÈáç„Åø„ÅØÂõ∫ÂÆö„Åô„Çã\n",
    "   \n",
    "# „Ç´„Çπ„Çø„É†ÂàÜÈ°ûÂ±§„Çí‰∏ä„Å´‰πó„Åõ„ÇãÔºàÊîπÂñÑÁâàÔºâ\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)  # „Éê„ÉÉ„ÉÅÊ≠£Ë¶èÂåñ„ÇíËøΩÂä†\n",
    "\n",
    "# „Çà„ÇäÊ∑±„ÅÑ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊßãÈÄ†\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # „Éê„ÉÉ„ÉÅÊ≠£Ë¶èÂåñ„ÇíËøΩÂä†\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # „Éê„ÉÉ„ÉÅÊ≠£Ë¶èÂåñ„ÇíËøΩÂä†\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # „Éê„ÉÉ„ÉÅÊ≠£Ë¶èÂåñ„ÇíËøΩÂä†\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# „É¢„Éá„É´ÂÆöÁæ©\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# ---------- Á¨¨1ÊÆµÈöé (ÂÖ®ÂáçÁµê) ----------\n",
    "model.compile(optimizer=Adam(1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks_stage1 = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=10,\n",
    "                  restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                      patience=5, min_lr=1e-7, verbose=1),\n",
    "    ModelCheckpoint('best_stage1.h5', monitor='val_accuracy',\n",
    "                    save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "history_1 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_stage1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ---------- Á¨¨2ÊÆµÈöé (Fine-tuning) ----------\n",
    "# Êú´Â∞æ30Â±§„Å†„ÅëÂ≠¶Áøí„Åï„Åõ„Çã\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(1e-5),   # lr „ÇíÂøÖ„ÅöÂ∞è„Åï„Åè\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks_stage2 = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=15,\n",
    "                  restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                      patience=7, min_lr=1e-8, verbose=1),\n",
    "    ModelCheckpoint('best_stage2_finetuned.h5', monitor='val_accuracy',\n",
    "                    save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "history_2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_stage2,\n",
    "    verbose=1,\n",
    "    initial_epoch=len(history_1.history['loss'])  # Á∂ö„Åç„Åã„Çâ\n",
    ")\n",
    "\n",
    "# ---------- ÊúÄÁµÇ„É¢„Éá„É´‰øùÂ≠ò ----------\n",
    "model.save('cat_dog_final.h5')\n",
    "# „É¢„Éá„É´„ÅÆË¶ÅÁ¥Ñ„ÇíË°®Á§∫\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ „É¢„Éá„É´Ë©ï‰æ°\n",
    "# \"validation\" „Éï„Ç©„É´„ÉÄ„ÅÆ‰∏≠„Å´„ÅÇ„ÇãÁîªÂÉè„Çí‰Ωø„Å£„Å¶„ÄÅ„É¢„Éá„É´„ÅÆË©ï‰æ°„ÇíË°å„ÅÜ\n",
    "# ‚ûä Ê§úË®ºÁî®„Ç∏„Çß„Éç„É¨„Éº„Çø„Éº„Çí‰ΩúÊàêÔºàshuffle=False „Åß„Éï„Ç°„Ç§„É´È†Ü„Å´ÂØæÂøúÔºâ\n",
    "# ÁîªÂÉè„Å´Êâã„ÇíÂä†„Åà„Åö„Å´„ÄÅ„Åù„ÅÆ„Åæ„ÅæÈ†ÜÁï™„Å´Âèñ„ÇäÂá∫„Åó„Å¶Ë©ï‰æ°„Åô„Çã\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,                  # Ê§úË®º„ÅØ„Ç∑„É£„ÉÉ„Éï„É´„Åó„Å™„ÅÑ\n",
    "    seed=seed_value \n",
    ")\n",
    "\n",
    "# ‚ûä „É¢„Éá„É´„ÅÆË©ï‰æ°ÔºàÊ§úË®º„Éá„Éº„ÇøÂÖ®‰Ωì„Åß„ÅÆÊúÄÁµÇÁöÑ„Å™ loss „Å® accuracy „ÇíÂèñÂæóÔºâ\n",
    "loss_eval, acc_eval = model.evaluate(val_gen, verbose=1)\n",
    "print(f\"‚ñ∂ ÊúÄÁµÇÊ§úË®ºÊêçÂ§±: {loss_eval:.4f}\")\n",
    "print(f\"‚ñ∂ ÊúÄÁµÇÊ§úË®ºÁ≤æÂ∫¶: {acc_eval:.4f}\")\n",
    "print(\"‚ñ∂ „É¢„Éá„É´„ÅÆË©ï‰æ°„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü\")\n",
    "\n",
    "from datetime import datetime\n",
    "fname = f\"cat_dog_{datetime.now():%Y%m%d_%H%M}_acc{acc_eval:.2f}.h5\"\n",
    "model.save(fname)\n",
    "print(f\"„É¢„Éá„É´„Çí {fname} „Å´‰øùÂ≠ò„Åó„Åæ„Åó„Åüüêæ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Â≠¶ÁøíÁµêÊûú„ÅÆÂèØË¶ñÂåñ\n",
    "import matplotlib.pyplot as plt\n",
    "# „Éï„Ç©„É≥„ÉàË®≠ÂÆöÔºà‰æãÔºöWindows + „É°„Ç§„É™„Ç™Ôºâ\n",
    "plt.rcParams['font.family'] = 'Meiryo'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def plot_training_history(history_1, history_2=None):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Á≤æÂ∫¶„ÅÆ„Éó„É≠„ÉÉ„Éà\n",
    "    epochs_1 = range(1, len(history_1.history['accuracy']) + 1)\n",
    "    ax1.plot(epochs_1, history_1.history['accuracy'], 'bo-', label='Training acc (Stage 1)')\n",
    "    ax1.plot(epochs_1, history_1.history['val_accuracy'], 'ro-', label='Validation acc (Stage 1)')\n",
    "    \n",
    "    if history_2:\n",
    "        epochs_2 = range(len(epochs_1) + 1, len(epochs_1) + len(history_2.history['accuracy']) + 1)\n",
    "        ax1.plot(epochs_2, history_2.history['accuracy'], 'bs-', label='Training acc (Stage 2)')\n",
    "        ax1.plot(epochs_2, history_2.history['val_accuracy'], 'rs-', label='Validation acc (Stage 2)')\n",
    "    \n",
    "    ax1.set_title('Model accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # ÊêçÂ§±„ÅÆ„Éó„É≠„ÉÉ„Éà\n",
    "    ax2.plot(epochs_1, history_1.history['loss'], 'bo-', label='Training loss (Stage 1)')\n",
    "    ax2.plot(epochs_1, history_1.history['val_loss'], 'ro-', label='Validation loss (Stage 1)')\n",
    "    \n",
    "    if history_2:\n",
    "        ax2.plot(epochs_2, history_2.history['loss'], 'bs-', label='Training loss (Stage 2)')\n",
    "        ax2.plot(epochs_2, history_2.history['val_loss'], 'rs-', label='Validation loss (Stage 2)')\n",
    "    \n",
    "    ax2.set_title('Model loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# „Ç∞„É©„Éï„ÇíË°®Á§∫\n",
    "plot_training_history(history_1, history_2)\n",
    "\n",
    "# 6. ‰∫àÊ∏¨ÁµêÊûú„Çí CSV „Å´Âá∫Âäõ\n",
    "import pandas as pd\n",
    "preds       = model.predict(val_gen, steps=len(val_gen), verbose=1)\n",
    "pred_labels = (preds >= 0.5).astype(int).flatten()\n",
    "true_labels = val_gen.classes\n",
    "filenames   = val_gen.filenames\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'true':     true_labels,\n",
    "    'pred':     pred_labels\n",
    "})\n",
    "df.attrs['param'] = {'epoch':EPOCHS, 'batch':BATCH_SIZE,\n",
    "                     'lr':1e-4, 'aug':'std'}\n",
    "df['correct'] = df['true'] == df['pred']\n",
    "df.to_csv('classification_results.csv', index=False)\n",
    "print(\"‚ñ∂ classification_results.csv „Å´Êõ∏„ÅçÂá∫„Åó„Åæ„Åó„Åü\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
