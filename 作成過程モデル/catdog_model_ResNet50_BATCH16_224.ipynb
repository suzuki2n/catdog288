{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# シード値を固定\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 🐱🐶 画像分類モデルの学習\n",
    "print(Sequential)\n",
    "# GPUがあるか確認して、あればメモリ制限\n",
    "print(device_lib.list_local_devices())\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"✅ GPUが見つかりました\")\n",
    "    try:\n",
    "        # 動的メモリ割り当てを有効化\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✅ GPUメモリの動的割り当てを設定しました\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"❌ メモリ設定に失敗しました：\", e)\n",
    "        \n",
    "# 🟡 ここに設定をまとめておくと便利！\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "BATCH_SIZE =16\n",
    "EPOCHS = 30 # 「全部の画像 × 3周」を学習\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)  # 画像の縦・横・チャンネル数\n",
    "\n",
    "train_dir = 'dataset/train'\n",
    "val_dir = 'dataset/validation'\n",
    "\n",
    "# 📁 データの前処理\n",
    "# 訓練用ジェネレーター（オーグメンテーション付き）\n",
    "# オーグメンテーション（回転やズームなど）をかけながら、ランダムに画像を取り出して学習させる\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# ディレクトリから画像を読み込む\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # 訓練データのパス\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=seed_value\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    "    seed=seed_value # 乱数シードを固定\n",
    "    # shuffle=False, # シャッフルしない場合は、Trueにするとエラーになるので注意\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 モデル構築\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ResNet50のベースモデル（ImageNet学習済み）を使う\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # 最初は凍結して特徴抽出器として使う\n",
    "\n",
    "# カスタム分類層を上に乗せる\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Flattenの代わりで軽量\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "# モデル定義\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# コンパイル\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"✅ ResNet50ベースのモデルが構築されました\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ コンパイル\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"✅ ResNet50ベースのモデルが構築されました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル学習\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor='val_loss',   # 何を監視するか\n",
    "    patience=5,           # 何エポック連続で改善しなければ止めるか\n",
    "    restore_best_weights=True,\n",
    "    verbose=1)\n",
    "\n",
    "reduce = ReduceLROnPlateau(\n",
    "    monitor='val_loss',   # 監視対象\n",
    "    factor=0.5,           # LR を 0.5 倍に\n",
    "    patience=2,           # 2 エポック改善しなければ発動\n",
    "    min_lr=1e-6,          # これ以下には下げない\n",
    "    verbose=1)\n",
    "\n",
    "try:\n",
    "    # バッチごとに処理を試す最小限の設定\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[early, reduce],\n",
    "        workers=1,\n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    print(\"✅ モデル学習が正常に完了しました\")\n",
    "    # 学習成功時にモデル保存\n",
    "    model.save('cat_dog_model.h5')\n",
    "    print(\"モデルを cat_dog_model.h5 に保存しました\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ エラーが発生しました: {str(e)}\")\n",
    "    model.save('cat_dog_model_error.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 モデル評価\n",
    "# \"validation\" フォルダの中にある画像を使って、モデルの評価を行うにゃ！\n",
    "# ➊ 検証用ジェネレーターを作成（shuffle=False でファイル順に対応）\n",
    "# 画像に手を加えずに、そのまま順番に取り出して評価する\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,                  # 検証はシャッフルしない\n",
    "    seed=seed_value \n",
    ")\n",
    "\n",
    "# ➊ モデルの評価（検証データ全体での最終的な loss と accuracy を取得）\n",
    "loss_eval, acc_eval = model.evaluate(val_gen, verbose=1)\n",
    "print(f\"▶ 最終検証損失: {loss_eval:.4f}\")\n",
    "print(f\"▶ 最終検証精度: {acc_eval:.4f}\")\n",
    "print(\"▶ モデルの評価が完了しましたにゃ！\")\n",
    "\n",
    "from datetime import datetime\n",
    "fname = f\"cat_dog_{datetime.now():%Y%m%d_%H%M}_acc{acc_eval:.2f}.h5\"\n",
    "model.save(fname)\n",
    "print(f\"モデルを {fname} に保存しました🐾\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 学習結果の可視化\n",
    "import matplotlib.pyplot as plt\n",
    "# フォント設定（例：Windows + メイリオ）\n",
    "plt.rcParams['font.family'] = 'Meiryo'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 学習過程の損失と精度をプロット\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 精度のグラフ\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='訓練精度')\n",
    "plt.plot(epochs_range, val_acc, label='検証精度')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('精度の推移')\n",
    "\n",
    "# 損失のグラフ\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='訓練損失')\n",
    "plt.plot(epochs_range, val_loss, label='検証損失')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('損失の推移')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 6. 予測結果を CSV に出力\n",
    "import pandas as pd\n",
    "preds       = model.predict(val_gen, steps=len(val_gen), verbose=1)\n",
    "pred_labels = (preds >= 0.5).astype(int).flatten()\n",
    "true_labels = val_gen.classes\n",
    "filenames   = val_gen.filenames\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'true':     true_labels,\n",
    "    'pred':     pred_labels\n",
    "})\n",
    "df.attrs['param'] = {'epoch':EPOCHS, 'batch':BATCH_SIZE,\n",
    "                     'lr':1e-4, 'aug':'std'}\n",
    "df['correct'] = df['true'] == df['pred']\n",
    "df.to_csv('classification_results.csv', index=False)\n",
    "print(\"▶ classification_results.csv に書き出しました\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
