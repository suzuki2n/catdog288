{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# コード先頭に追加\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# シード値を固定\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 🐱🐶 画像分類モデルの学習\n",
    "print(Sequential)\n",
    "# GPUがあるか確認して、あればメモリ制限\n",
    "print(device_lib.list_local_devices())\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"✅ GPUが見つかりました\")\n",
    "    try:\n",
    "        # 動的メモリ割り当てを有効化\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✅ GPUメモリの動的割り当てを設定しました\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"❌ メモリ設定に失敗しました：\", e)\n",
    "        \n",
    "# 🟡 ここに設定をまとめる\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "BATCH_SIZE =16\n",
    "EPOCHS = 25 # 「全部の画像 × 3周」を学習\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)  # 画像の縦・横・チャンネル数\n",
    "\n",
    "train_dir = 'dataset/train'\n",
    "val_dir = 'dataset/validation'\n",
    "\n",
    "# 📁 データの前処理\n",
    "'''\n",
    "「画像の画素値を 0〜1の範囲に正規化 するよ！」という設定\n",
    "元の画像って、1ピクセルあたり 0〜255 の値を持ってるけど\n",
    "→ ニューラルネットは 小さい値の方が学習しやすいので\n",
    "→ 0〜1の範囲に収めることで学習がスムーズに進む\n",
    "datagenはこれは開発者が自由に付けてる変数名だけど、\n",
    "data + generator = datagen って感じで「データを生成するもの」\n",
    "train_datagen → 学習用のデータを生成してくれるオブジェクト\n",
    "val_datagen → 検証用の画像は変形せず、正規化だけして使うことが多い\n",
    "'''\n",
    "# 訓練用ジェネレーター（オーグメンテーション付き）\n",
    "# オーグメンテーション（回転やズームなど）をかけながら、ランダムに画像を取り出して学習させる\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# ディレクトリから画像を読み込む\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # 訓練データのパス\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 モデル構築\n",
    "\n",
    "model = Sequential([\n",
    "    # 第1層: 畳み込み + 活性化 + プーリング\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=INPUT_SHAPE),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # 第2層: 畳み込み + 活性化 + プーリング（レイヤーを増やすことで特徴抽出の精度が向上する）\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),  # 中間に追加ニャ！\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(500, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    # BatchNormalization()は、学習を安定させるためのもの\n",
    "    # 平坦化して全結合層へ\n",
    "    Flatten(),\n",
    "\n",
    "    # 全結合層\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),  # 過学習対策としてDropoutを追加する\n",
    "    Dense(1, activation='sigmoid')  # 2クラス分類なのでシグモイド\n",
    "])\n",
    "\n",
    "print(\"モデルの構築が完了しました！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ コンパイル\n",
    "# 二値分類問題なので、binary_crossentropyを使う\n",
    "#11分類になったら categorical_crossentropy + class_mode='categorical' に変更必要\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"モデルのコンパイルが完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル学習 \n",
    "try:\n",
    "    # バッチごとに処理を試す最小限の設定\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_generator,\n",
    "        workers=1,\n",
    "        use_multiprocessing=False\n",
    "    )\n",
    "    print(\"✅ モデル学習が正常に完了しました\")\n",
    "    \n",
    "    # 学習成功時にモデル保存\n",
    "    model.save('cat_dog_model.h5')\n",
    "    print(\"モデルを cat_dog_model.h5 に保存しました\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ エラーが発生しました: {str(e)}\")\n",
    "    model.save('cat_dog_model_error.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧪 モデル評価\n",
    "# \"validation\" フォルダの中にある画像を使って、モデルの評価を行う\n",
    "# ➊ 検証用ジェネレーターを作成（shuffle=False でファイル順に対応）\n",
    "# 画像に手を加えずに、そのまま順番に取り出して評価する\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ➊ モデルの評価（検証データ全体での最終的な loss と accuracy を取得）\n",
    "loss_eval, acc_eval = model.evaluate(val_gen, verbose=1)\n",
    "print(f\"▶ 最終検証損失: {loss_eval:.4f}\")\n",
    "print(f\"▶ 最終検証精度: {acc_eval:.4f}\")\n",
    "print(\"▶ モデルの評価が完了しました\")\n",
    "\n",
    "from datetime import datetime\n",
    "fname = f\"cat_dog_{datetime.now():%Y%m%d_%H%M}_acc{acc_eval:.2f}.h5\"\n",
    "model.save(fname)\n",
    "print(f\"モデルを {fname} に保存しました🐾\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 学習結果の可視化\n",
    "import matplotlib.pyplot as plt\n",
    "# フォント設定（例：Windows + メイリオ）\n",
    "plt.rcParams['font.family'] = 'Meiryo'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 学習過程の損失と精度をプロット\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 精度のグラフ\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='訓練精度')\n",
    "plt.plot(epochs_range, val_acc, label='検証精度')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('精度の推移')\n",
    "\n",
    "# 損失のグラフ\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='訓練損失')\n",
    "plt.plot(epochs_range, val_loss, label='検証損失')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('損失の推移')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 6. 予測結果を CSV に出力\n",
    "import pandas as pd\n",
    "preds       = model.predict(val_gen, steps=len(val_gen), verbose=1)\n",
    "pred_labels = (preds >= 0.5).astype(int).flatten()\n",
    "true_labels = val_gen.classes\n",
    "filenames   = val_gen.filenames\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'true':     true_labels,\n",
    "    'pred':     pred_labels\n",
    "})\n",
    "df['correct'] = df['true'] == df['pred']\n",
    "df.to_csv('classification_results.csv', index=False)\n",
    "print(\"▶ classification_results.csv に書き出しました\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
